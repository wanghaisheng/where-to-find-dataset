---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Xinyi Wang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-03-17 11:38:44'
tags:
- dataset
- all search terms
theme: light
title: ASMATune Unlocking LLMs Assembly Code Comprehension via StructuralSemantic
  Instruction Tuning
---

# title: ASMATune Unlocking LLMs Assembly Code Comprehension via StructuralSemantic Instruction Tuning 
## publish date: 
**2025-03-14** 
## authors: 
  Xinyi Wang et.al. 
## paper id
2503.11617v1
## download
[2503.11617v1](http://arxiv.org/abs/2503.11617v1)
## abstracts:
Analysis and comprehension of assembly code are crucial in various applications, such as reverse engineering. However, the low information density and lack of explicit syntactic structures in assembly code pose significant challenges. Pioneering approaches with masked language modeling (MLM)-based methods have been limited by facilitating natural language interaction. While recent methods based on decoder-focused large language models (LLMs) have significantly enhanced semantic representation, they still struggle to capture the nuanced and sparse semantics in assembly code. In this paper, we propose Assembly Augmented Tuning (ASMA-Tune), an end-to-end structural-semantic instruction-tuning framework. Our approach synergizes encoder architectures with decoder-based LLMs through projector modules to enable comprehensive code understanding. Experiments show that ASMA-Tune outperforms existing benchmarks, significantly enhancing assembly code comprehension and instruction-following abilities. Our model and dataset are public at https://github.com/wxy3596/ASMA-Tune.
## QA:
coming soon
