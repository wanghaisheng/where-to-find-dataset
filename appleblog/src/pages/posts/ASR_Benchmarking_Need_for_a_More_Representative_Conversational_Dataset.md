---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Gaurav Maheshwari et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-09-23 11:35:18'
tags:
- dataset
- all search terms
theme: light
title: ASR Benchmarking Need for a More Representative Conversational Dataset
---

# title: ASR Benchmarking Need for a More Representative Conversational Dataset 
## publish date: 
**2024-09-18** 
## authors: 
  Gaurav Maheshwari et.al. 
## paper id
2409.12042v1
## download
[2409.12042v1](http://arxiv.org/abs/2409.12042v1)
## abstracts:
Automatic Speech Recognition (ASR) systems have achieved remarkable performance on widely used benchmarks such as LibriSpeech and Fleurs. However, these benchmarks do not adequately reflect the complexities of real-world conversational environments, where speech is often unstructured and contains disfluencies such as pauses, interruptions, and diverse accents. In this study, we introduce a multilingual conversational dataset, derived from TalkBank, consisting of unstructured phone conversation between adults. Our results show a significant performance drop across various state-of-the-art ASR models when tested in conversational settings. Furthermore, we observe a correlation between Word Error Rate and the presence of speech disfluencies, highlighting the critical need for more realistic, conversational ASR benchmarks.
## QA:
coming soon
