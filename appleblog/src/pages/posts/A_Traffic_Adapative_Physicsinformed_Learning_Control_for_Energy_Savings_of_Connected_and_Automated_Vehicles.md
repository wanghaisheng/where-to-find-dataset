---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Yunli Shao et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-23 11:35:40'
tags:
- all search terms
- dataset
theme: light
title: A Traffic Adapative Physicsinformed Learning Control for Energy Savings of
  Connected and Automated Vehicles
---

# title: A Traffic Adapative Physicsinformed Learning Control for Energy Savings of Connected and Automated Vehicles 
## publish date: 
**2024-12-19** 
## authors: 
  Yunli Shao et.al. 
## paper id
2412.15079v1
## download
[2412.15079v1](http://arxiv.org/abs/2412.15079v1)
## abstracts:
Model predictive control has emerged as an effective approach for real-time optimal control of connected and automated vehicles. However, nonlinear dynamics of vehicle and traffic systems make accurate modeling and real-time optimization challenging. Learning-based control offer a promising alternative, as they adapt to environment without requiring an explicit model. For learning control framework, an augmented state space system design is necessary since optimal control depends on both the ego vehicle's state and predicted states of other vehicles. This work develops a traffic adaptive augmented state space system that allows the control strategy to intelligently adapt to varying traffic conditions. This design ensures that while different vehicle trajectories alter initial conditions, the system dynamics remain independent of specific trajectories. Additionally, a physics-informed learning control framework is presented that combines value function from Bellman's equation with derivative of value functions from Pontryagin's Maximum Principle into a unified loss function. This method aims to reduce required training data and time while enhancing robustness and efficiency. The proposed control framework is applied to car-following scenarios in real-world data calibrated simulation environments. The results show that this learning control approach alleviates real-time computational requirements while achieving car-following behaviors comparable to model-based methods, resulting in 9% energy savings in scenarios not previously seen in training dataset.
## QA:
coming soon
