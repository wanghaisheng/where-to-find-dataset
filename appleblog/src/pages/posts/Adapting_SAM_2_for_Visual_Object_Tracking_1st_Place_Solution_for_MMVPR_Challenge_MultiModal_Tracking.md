---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Cheng-Yen Yang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-05-26 11:44:17'
tags:
- dataset
- all search terms
theme: light
title: Adapting SAM 2 for Visual Object Tracking 1st Place Solution for MMVPR Challenge
  MultiModal Tracking
---

# title: Adapting SAM 2 for Visual Object Tracking 1st Place Solution for MMVPR Challenge MultiModal Tracking 
## publish date: 
**2025-05-23** 
## authors: 
  Cheng-Yen Yang et.al. 
## paper id
2505.18111v1
## download
[2505.18111v1](http://arxiv.org/abs/2505.18111v1)
## abstracts:
We present an effective approach for adapting the Segment Anything Model 2 (SAM2) to the Visual Object Tracking (VOT) task. Our method leverages the powerful pre-trained capabilities of SAM2 and incorporates several key techniques to enhance its performance in VOT applications. By combining SAM2 with our proposed optimizations, we achieved a first place AUC score of 89.4 on the 2024 ICPR Multi-modal Object Tracking challenge, demonstrating the effectiveness of our approach. This paper details our methodology, the specific enhancements made to SAM2, and a comprehensive analysis of our results in the context of VOT solutions along with the multi-modality aspect of the dataset.
## QA:
coming soon
