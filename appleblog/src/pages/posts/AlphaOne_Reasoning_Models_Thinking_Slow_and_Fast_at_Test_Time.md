---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Junyu Zhang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-06-02 11:45:59'
tags:
- dataset on github
- all search terms
theme: light
title: AlphaOne Reasoning Models Thinking Slow and Fast at Test Time
---

# title: AlphaOne Reasoning Models Thinking Slow and Fast at Test Time 
## publish date: 
**2025-05-30** 
## authors: 
  Junyu Zhang et.al. 
## paper id
2505.24863v1
## download
[2505.24863v1](http://arxiv.org/abs/2505.24863v1)
## abstracts:
This paper presents AlphaOne ($\alpha$1), a universal framework for modulating reasoning progress in large reasoning models (LRMs) at test time. $\alpha$1 first introduces $\alpha$ moment, which represents the scaled thinking phase with a universal parameter $\alpha$. Within this scaled pre-$\alpha$ moment phase, it dynamically schedules slow thinking transitions by modeling the insertion of reasoning transition tokens as a Bernoulli stochastic process. After the $\alpha$ moment, $\alpha$1 deterministically terminates slow thinking with the end-of-thinking token, thereby fostering fast reasoning and efficient answer generation. This approach unifies and generalizes existing monotonic scaling methods by enabling flexible and dense slow-to-fast reasoning modulation. Extensive empirical studies on various challenging benchmarks across mathematical, coding, and scientific domains demonstrate $\alpha$1's superior reasoning capability and efficiency. Project page: https://alphaone-project.github.io/
## QA:
coming soon
