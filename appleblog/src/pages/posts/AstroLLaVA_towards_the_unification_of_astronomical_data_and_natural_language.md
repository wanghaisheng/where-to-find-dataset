---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Sharaf Zaman et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-04-14 11:41:16'
tags:
- dataset
- all search terms
theme: light
title: AstroLLaVA towards the unification of astronomical data and natural language
---

# title: AstroLLaVA towards the unification of astronomical data and natural language 
## publish date: 
**2025-04-11** 
## authors: 
  Sharaf Zaman et.al. 
## paper id
2504.08583v1
## download
[2504.08583v1](http://arxiv.org/abs/2504.08583v1)
## abstracts:
We present AstroLLaVA, a vision language model for astronomy that enables interaction with astronomical imagery through natural dialogue. By fine-tuning the LLaVA model on a diverse dataset of $\sim$30k images with captions and question-answer pairs sourced from NASA's `Astronomy Picture of the Day', the European Southern Observatory, and the NASA/ESA Hubble Space Telescope, we create a model capable of answering open-ended questions about astronomical concepts depicted visually. Our two-stage fine-tuning process adapts the model to both image captioning and visual question answering in the astronomy domain. We demonstrate AstroLLaVA's performance on an astronomical visual question answering benchmark and release the model weights, code, and training set to encourage further open source work in this space. Finally, we suggest a roadmap towards general astronomical data alignment with pre-trained language models, and provide an open space for collaboration towards this end for interested researchers.
## QA:
coming soon
