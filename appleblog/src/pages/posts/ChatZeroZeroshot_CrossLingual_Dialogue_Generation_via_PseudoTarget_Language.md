---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Yongkang Liu et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-19 11:32:24'
tags:
- all search terms
- dataset
theme: light
title: ChatZeroZeroshot CrossLingual Dialogue Generation via PseudoTarget Language
---

# title: ChatZeroZeroshot CrossLingual Dialogue Generation via PseudoTarget Language 
## publish date: 
**2024-08-16** 
## authors: 
  Yongkang Liu et.al. 
## paper id
2408.08724v1
## download
[2408.08724v1](http://arxiv.org/abs/2408.08724v1)
## abstracts:
Although large language models(LLMs) show amazing capabilities, among various exciting applications discovered for LLMs fall short in other low-resource languages. Besides, most existing methods depend on large-scale dialogue corpora and thus building systems for dialogue generation in a zero-shot scenario remains a considerable challenge. To address this challenge, we propose a novel end-to-end zero-shot dialogue generation model ChatZero based on cross-lingual code-switching method. First, we construct code-switching language and pseudo-target language with placeholders. Then for cross-lingual semantic transfer, we employ unsupervised contrastive learning to minimize the semantics gap of the source language, code-switching language, and pseudo-target language that are mutually positive examples in the high dimensional semantic space. Experiments on the multilingual DailyDialog and DSTC7-AVSD datasets demonstrate that ChatZero can achieve more than 90\% of the original performance under the zero-shot case compared to supervised learning, and achieve state-of-the-art performance compared with other baselines.
## QA:
coming soon
