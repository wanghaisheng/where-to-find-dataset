---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Youngsik Yun et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-05-05 11:43:19'
tags:
- all search terms
- dataset
theme: light
title: Compensating Spatiotemporally Inconsistent Observations for Online Dynamic
  3D Gaussian Splatting
---

# title: Compensating Spatiotemporally Inconsistent Observations for Online Dynamic 3D Gaussian Splatting 
## publish date: 
**2025-05-02** 
## authors: 
  Youngsik Yun et.al. 
## paper id
2505.01235v1
## download
[2505.01235v1](http://arxiv.org/abs/2505.01235v1)
## abstracts:
Online reconstruction of dynamic scenes is significant as it enables learning scenes from live-streaming video inputs, while existing offline dynamic reconstruction methods rely on recorded video inputs. However, previous online reconstruction approaches have primarily focused on efficiency and rendering quality, overlooking the temporal consistency of their results, which often contain noticeable artifacts in static regions. This paper identifies that errors such as noise in real-world recordings affect temporal inconsistency in online reconstruction. We propose a method that enhances temporal consistency in online reconstruction from observations with temporal inconsistency which is inevitable in cameras. We show that our method restores the ideal observation by subtracting the learned error. We demonstrate that applying our method to various baselines significantly enhances both temporal consistency and rendering quality across datasets. Code, video results, and checkpoints are available at https://bbangsik13.github.io/OR2.
## QA:
coming soon
