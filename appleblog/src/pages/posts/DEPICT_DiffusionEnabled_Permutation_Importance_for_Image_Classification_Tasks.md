---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Sarah Jabbour et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-07-22 11:32:48'
tags:
- all search terms
- dataset on github
theme: light
title: DEPICT DiffusionEnabled Permutation Importance for Image Classification Tasks
---

# title: DEPICT DiffusionEnabled Permutation Importance for Image Classification Tasks 
## publish date: 
**2024-07-19** 
## authors: 
  Sarah Jabbour et.al. 
## paper id
2407.14509v1
## download
[2407.14509v1](http://arxiv.org/abs/2407.14509v1)
## abstracts:
We propose a permutation-based explanation method for image classifiers. Current image-model explanations like activation maps are limited to instance-based explanations in the pixel space, making it difficult to understand global model behavior. In contrast, permutation based explanations for tabular data classifiers measure feature importance by comparing model performance on data before and after permuting a feature. We propose an explanation method for image-based models that permutes interpretable concepts across dataset images. Given a dataset of images labeled with specific concepts like captions, we permute a concept across examples in the text space and then generate images via a text-conditioned diffusion model. Feature importance is then reflected by the change in model performance relative to unpermuted data. When applied to a set of concepts, the method generates a ranking of feature importance. We show this approach recovers underlying model feature importance on synthetic and real-world image classification tasks.
## QA:
coming soon
