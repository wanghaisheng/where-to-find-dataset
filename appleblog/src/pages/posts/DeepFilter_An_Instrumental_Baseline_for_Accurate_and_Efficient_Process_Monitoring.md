---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Hao Wang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-01-06 11:37:00'
tags:
- all search terms
- dataset
theme: light
title: DeepFilter An Instrumental Baseline for Accurate and Efficient Process Monitoring
---

# title: DeepFilter An Instrumental Baseline for Accurate and Efficient Process Monitoring 
## publish date: 
**2025-01-02** 
## authors: 
  Hao Wang et.al. 
## paper id
2501.01342v1
## download
[2501.01342v1](http://arxiv.org/abs/2501.01342v1)
## abstracts:
Effective process monitoring is increasingly vital in industrial automation for ensuring operational safety, necessitating both high accuracy and efficiency. Although Transformers have demonstrated success in various fields, their canonical form based on the self-attention mechanism is inadequate for process monitoring due to two primary limitations: (1) the step-wise correlations captured by self-attention mechanism are difficult to capture discriminative patterns in monitoring logs due to the lacking semantics of each step, thus compromising accuracy; (2) the quadratic computational complexity of self-attention hampers efficiency. To address these issues, we propose DeepFilter, a Transformer-style framework for process monitoring. The core innovation is an efficient filtering layer that excel capturing long-term and periodic patterns with reduced complexity. Equipping with the global filtering layer, DeepFilter enhances both accuracy and efficiency, meeting the stringent demands of process monitoring. Experimental results on real-world process monitoring datasets validate DeepFilter's superiority in terms of accuracy and efficiency compared to existing state-of-the-art models.
## QA:
coming soon
