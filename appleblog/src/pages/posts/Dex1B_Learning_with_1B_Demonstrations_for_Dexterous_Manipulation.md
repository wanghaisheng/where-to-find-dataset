---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Jianglong Ye et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-06-23 11:47:41'
tags:
- all search terms
- dataset
theme: light
title: Dex1B Learning with 1B Demonstrations for Dexterous Manipulation
---

# title: Dex1B Learning with 1B Demonstrations for Dexterous Manipulation 
## publish date: 
**2025-06-20** 
## authors: 
  Jianglong Ye et.al. 
## paper id
2506.17198v1
## download
[2506.17198v1](http://arxiv.org/abs/2506.17198v1)
## abstracts:
Generating large-scale demonstrations for dexterous hand manipulation remains challenging, and several approaches have been proposed in recent years to address this. Among them, generative models have emerged as a promising paradigm, enabling the efficient creation of diverse and physically plausible demonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and high-quality demonstration dataset produced with generative models. The dataset contains one billion demonstrations for two fundamental tasks: grasping and articulation. To construct it, we propose a generative model that integrates geometric constraints to improve feasibility and applies additional conditions to enhance diversity. We validate the model on both established and newly introduced simulation benchmarks, where it significantly outperforms prior state-of-the-art methods. Furthermore, we demonstrate its effectiveness and robustness through real-world robot experiments. Our project page is at https://jianglongye.com/dex1b
## QA:
coming soon
