---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Andrea Rigo et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-04-21 11:43:01'
tags:
- all search terms
- dataset
theme: light
title: ESPLoRA Enhanced Spatial Precision with LowRank Adaption in TexttoImage Diffusion
  Models for HighDefinition Synthesis
---

# title: ESPLoRA Enhanced Spatial Precision with LowRank Adaption in TexttoImage Diffusion Models for HighDefinition Synthesis 
## publish date: 
**2025-04-18** 
## authors: 
  Andrea Rigo et.al. 
## paper id
2504.13745v1
## download
[2504.13745v1](http://arxiv.org/abs/2504.13745v1)
## abstracts:
Diffusion models have revolutionized text-to-image (T2I) synthesis, producing high-quality, photorealistic images. However, they still struggle to properly render the spatial relationships described in text prompts. To address the lack of spatial information in T2I generations, existing methods typically use external network conditioning and predefined layouts, resulting in higher computational costs and reduced flexibility. Our approach builds upon a curated dataset of spatially explicit prompts, meticulously extracted and synthesized from LAION-400M to ensure precise alignment between textual descriptions and spatial layouts. Alongside this dataset, we present ESPLoRA, a flexible fine-tuning framework based on Low-Rank Adaptation, specifically designed to enhance spatial consistency in generative models without increasing generation time or compromising the quality of the outputs. In addition to ESPLoRA, we propose refined evaluation metrics grounded in geometric constraints, capturing 3D spatial relations such as \textit{in front of} or \textit{behind}. These metrics also expose spatial biases in T2I models which, even when not fully mitigated, can be strategically exploited by our TORE algorithm to further improve the spatial consistency of generated images. Our method outperforms the current state-of-the-art framework, CoMPaSS, by 13.33% on established spatial consistency benchmarks.
## QA:
coming soon
