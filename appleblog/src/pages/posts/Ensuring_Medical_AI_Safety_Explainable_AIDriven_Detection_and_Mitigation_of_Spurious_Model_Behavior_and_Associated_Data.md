---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Frederik Pahde et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-01-27 11:33:59'
tags:
- all search terms
- dataset
theme: light
title: Ensuring Medical AI Safety Explainable AIDriven Detection and Mitigation of
  Spurious Model Behavior and Associated Data
---

# title: Ensuring Medical AI Safety Explainable AIDriven Detection and Mitigation of Spurious Model Behavior and Associated Data 
## publish date: 
**2025-01-23** 
## authors: 
  Frederik Pahde et.al. 
## paper id
2501.13818v1
## download
[2501.13818v1](http://arxiv.org/abs/2501.13818v1)
## abstracts:
Deep neural networks are increasingly employed in high-stakes medical applications, despite their tendency for shortcut learning in the presence of spurious correlations, which can have potentially fatal consequences in practice. Detecting and mitigating shortcut behavior is a challenging task that often requires significant labeling efforts from domain experts. To alleviate this problem, we introduce a semi-automated framework for the identification of spurious behavior from both data and model perspective by leveraging insights from eXplainable Artificial Intelligence (XAI). This allows the retrieval of spurious data points and the detection of model circuits that encode the associated prediction rules. Moreover, we demonstrate how these shortcut encodings can be used for XAI-based sample- and pixel-level data annotation, providing valuable information for bias mitigation methods to unlearn the undesired shortcut behavior. We show the applicability of our framework using four medical datasets across two modalities, featuring controlled and real-world spurious correlations caused by data artifacts. We successfully identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision Transformer models, ultimately increasing their robustness and applicability for real-world medical tasks.
## QA:
coming soon
