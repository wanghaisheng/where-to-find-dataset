---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Shuqi Dai et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-01-27 11:33:55'
tags:
- all search terms
- dataset
theme: light
title: EveryoneCanSing ZeroShot Singing Voice Synthesis and Conversion with Speech
  Reference
---

# title: EveryoneCanSing ZeroShot Singing Voice Synthesis and Conversion with Speech Reference 
## publish date: 
**2025-01-23** 
## authors: 
  Shuqi Dai et.al. 
## paper id
2501.13870v1
## download
[2501.13870v1](http://arxiv.org/abs/2501.13870v1)
## abstracts:
We propose a unified framework for Singing Voice Synthesis (SVS) and Conversion (SVC), addressing the limitations of existing approaches in cross-domain SVS/SVC, poor output musicality, and scarcity of singing data. Our framework enables control over multiple aspects, including language content based on lyrics, performance attributes based on a musical score, singing style and vocal techniques based on a selector, and voice identity based on a speech sample. The proposed zero-shot learning paradigm consists of one SVS model and two SVC models, utilizing pre-trained content embeddings and a diffusion-based generator. The proposed framework is also trained on mixed datasets comprising both singing and speech audio, allowing singing voice cloning based on speech reference. Experiments show substantial improvements in timbre similarity and musicality over state-of-the-art baselines, providing insights into other low-data music tasks such as instrumental style transfer. Examples can be found at: everyone-can-sing.github.io.
## QA:
coming soon
