---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Sebastian Niehaus et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-24 01:27:49'
tags:
- all search terms
- dataset
theme: light
title: Fair Distributed Machine Learning with Imbalanced Data as a Stackelberg Evolutionary
  Game
---

# title: Fair Distributed Machine Learning with Imbalanced Data as a Stackelberg Evolutionary Game 
## publish date: 
**2024-12-20** 
## authors: 
  Sebastian Niehaus et.al. 
## paper id
2412.16079v1
## download
[2412.16079v1](http://arxiv.org/abs/2412.16079v1)
## abstracts:
Decentralised learning enables the training of deep learning algorithms without centralising data sets, resulting in benefits such as improved data privacy, operational efficiency and the fostering of data ownership policies. However, significant data imbalances pose a challenge in this framework. Participants with smaller datasets in distributed learning environments often achieve poorer results than participants with larger datasets. Data imbalances are particularly pronounced in medical fields and are caused by different patient populations, technological inequalities and divergent data collection practices.   In this paper, we consider distributed learning as an Stackelberg evolutionary game. We present two algorithms for setting the weights of each node's contribution to the global model in each training round: the Deterministic Stackelberg Weighting Model (DSWM) and the Adaptive Stackelberg Weighting Model (ASWM). We use three medical datasets to highlight the impact of dynamic weighting on underrepresented nodes in distributed learning. Our results show that the ASWM significantly favours underrepresented nodes by improving their performance by 2.713% in AUC. Meanwhile, nodes with larger datasets experience only a modest average performance decrease of 0.441%.
## QA:
coming soon
