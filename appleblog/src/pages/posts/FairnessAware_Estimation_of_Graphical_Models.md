---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Zhuoping Zhou et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-09-02 11:33:05'
tags:
- dataset
- all search terms
theme: light
title: FairnessAware Estimation of Graphical Models
---

# title: FairnessAware Estimation of Graphical Models 
## publish date: 
**2024-08-30** 
## authors: 
  Zhuoping Zhou et.al. 
## paper id
2408.17396v1
## download
[2408.17396v1](http://arxiv.org/abs/2408.17396v1)
## abstracts:
This paper examines the issue of fairness in the estimation of graphical models (GMs), particularly Gaussian, Covariance, and Ising models. These models play a vital role in understanding complex relationships in high-dimensional data. However, standard GMs can result in biased outcomes, especially when the underlying data involves sensitive characteristics or protected groups. To address this, we introduce a comprehensive framework designed to reduce bias in the estimation of GMs related to protected attributes. Our approach involves the integration of the pairwise graph disparity error and a tailored loss function into a nonsmooth multi-objective optimization problem, striving to achieve fairness across different sensitive groups while maintaining the effectiveness of the GMs. Experimental evaluations on synthetic and real-world datasets demonstrate that our framework effectively mitigates bias without undermining GMs' performance.
## QA:
coming soon
