---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Tianzhe Xiao et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-30 11:35:42'
tags:
- all search terms
- dataset
theme: light
title: FedGIG Graph Inversion from Gradient in Federated Learning
---

# title: FedGIG Graph Inversion from Gradient in Federated Learning 
## publish date: 
**2024-12-24** 
## authors: 
  Tianzhe Xiao et.al. 
## paper id
2412.18513v1
## download
[2412.18513v1](http://arxiv.org/abs/2412.18513v1)
## abstracts:
Recent studies have shown that Federated learning (FL) is vulnerable to Gradient Inversion Attacks (GIA), which can recover private training data from shared gradients. However, existing methods are designed for dense, continuous data such as images or vectorized texts, and cannot be directly applied to sparse and discrete graph data. This paper first explores GIA's impact on Federated Graph Learning (FGL) and introduces Graph Inversion from Gradient in Federated Learning (FedGIG), a novel GIA method specifically designed for graph-structured data. FedGIG includes the adjacency matrix constraining module, which ensures the sparsity and discreteness of the reconstructed graph data, and the subgraph reconstruction module, which is designed to complete missing common subgraph structures. Extensive experiments on molecular datasets demonstrate FedGIG's superior accuracy over existing GIA techniques.
## QA:
coming soon
