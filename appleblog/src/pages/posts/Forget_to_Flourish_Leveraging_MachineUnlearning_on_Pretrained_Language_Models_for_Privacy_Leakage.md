---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Md Rafi Ur Rashid et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-09-02 11:33:06'
tags:
- dataset
- all search terms
theme: light
title: Forget to Flourish Leveraging MachineUnlearning on Pretrained Language Models
  for Privacy Leakage
---

# title: Forget to Flourish Leveraging MachineUnlearning on Pretrained Language Models for Privacy Leakage 
## publish date: 
**2024-08-30** 
## authors: 
  Md Rafi Ur Rashid et.al. 
## paper id
2408.17354v1
## download
[2408.17354v1](http://arxiv.org/abs/2408.17354v1)
## abstracts:
Fine-tuning large language models on private data for downstream applications poses significant privacy risks in potentially exposing sensitive information. Several popular community platforms now offer convenient distribution of a large variety of pre-trained models, allowing anyone to publish without rigorous verification. This scenario creates a privacy threat, as pre-trained models can be intentionally crafted to compromise the privacy of fine-tuning datasets. In this study, we introduce a novel poisoning technique that uses model-unlearning as an attack tool. This approach manipulates a pre-trained language model to increase the leakage of private data during the fine-tuning process. Our method enhances both membership inference and data extraction attacks while preserving model utility. Experimental results across different models, datasets, and fine-tuning setups demonstrate that our attacks significantly surpass baseline performance. This work serves as a cautionary note for users who download pre-trained models from unverified sources, highlighting the potential risks involved.
## QA:
coming soon
