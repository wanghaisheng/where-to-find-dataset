---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Xincheng Shuai et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-01-06 11:36:57'
tags:
- all search terms
- dataset
theme: light
title: FreeForm Motion Control A Synthetic Video Generation Dataset with Controllable
  Camera and Object Motions
---

# title: FreeForm Motion Control A Synthetic Video Generation Dataset with Controllable Camera and Object Motions 
## publish date: 
**2025-01-02** 
## authors: 
  Xincheng Shuai et.al. 
## paper id
2501.01425v2
## download
[2501.01425v2](http://arxiv.org/abs/2501.01425v2)
## abstracts:
Controlling the movements of dynamic objects and the camera within generated videos is a meaningful yet challenging task. Due to the lack of datasets with comprehensive motion annotations, existing algorithms can not simultaneously control the motions of both camera and objects, resulting in limited controllability over generated contents. To address this issue and facilitate the research in this field, we introduce a Synthetic Dataset for Free-Form Motion Control (SynFMC). The proposed SynFMC dataset includes diverse objects and environments and covers various motion patterns according to specific rules, simulating common and complex real-world scenarios. The complete 6D pose information facilitates models learning to disentangle the motion effects from objects and the camera in a video. To validate the effectiveness and generalization of SynFMC, we further propose a method, Free-Form Motion Control (FMC). FMC enables independent or simultaneous control of object and camera movements, producing high-fidelity videos. Moreover, it is compatible with various personalized text-to-image (T2I) models for different content styles. Extensive experiments demonstrate that the proposed FMC outperforms previous methods across multiple scenarios.
## QA:
coming soon
