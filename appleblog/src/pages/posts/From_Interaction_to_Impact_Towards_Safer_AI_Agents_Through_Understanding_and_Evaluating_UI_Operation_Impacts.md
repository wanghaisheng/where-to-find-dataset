---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Zhuohao Jerry Zhang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-10-14 11:37:30'
tags:
- all search terms
- dataset
theme: light
title: From Interaction to Impact Towards Safer AI Agents Through Understanding and
  Evaluating UI Operation Impacts
---

# title: From Interaction to Impact Towards Safer AI Agents Through Understanding and Evaluating UI Operation Impacts 
## publish date: 
**2024-10-11** 
## authors: 
  Zhuohao Jerry Zhang et.al. 
## paper id
2410.09006v1
## download
[2410.09006v1](http://arxiv.org/abs/2410.09006v1)
## abstracts:
With advances in generative AI, there is increasing work towards creating autonomous agents that can manage daily tasks by operating user interfaces (UIs). While prior research has studied the mechanics of how AI agents might navigate UIs and understand UI structure, the effects of agents and their autonomous actions-particularly those that may be risky or irreversible-remain under-explored. In this work, we investigate the real-world impacts and consequences of UI actions by AI agents. We began by developing a taxonomy of the impacts of UI actions through a series of workshops with domain experts. Following this, we conducted a data synthesis study to gather realistic UI screen traces and action data that users perceive as impactful. We then used our impact categories to annotate our collected data and data repurposed from existing UI navigation datasets. Our quantitative evaluations of different large language models (LLMs) and variants demonstrate how well different LLMs can understand the impacts of UI actions that might be taken by an agent. We show that our taxonomy enhances the reasoning capabilities of these LLMs for understanding the impacts of UI actions, but our findings also reveal significant gaps in their ability to reliably classify more nuanced or complex categories of impact.
## QA:
coming soon
