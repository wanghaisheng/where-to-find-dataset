---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Hosam Elgendy et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-10-28 11:38:10'
tags:
- all search terms
- dataset
theme: light
title: GeoLLaVA Efficient FineTuned VisionLanguage Models for Temporal Change Detection
  in Remote Sensing
---

# title: GeoLLaVA Efficient FineTuned VisionLanguage Models for Temporal Change Detection in Remote Sensing 
## publish date: 
**2024-10-25** 
## authors: 
  Hosam Elgendy et.al. 
## paper id
2410.19552v1
## download
[2410.19552v1](http://arxiv.org/abs/2410.19552v1)
## abstracts:
Detecting temporal changes in geographical landscapes is critical for applications like environmental monitoring and urban planning. While remote sensing data is abundant, existing vision-language models (VLMs) often fail to capture temporal dynamics effectively. This paper addresses these limitations by introducing an annotated dataset of video frame pairs to track evolving geographical patterns over time. Using fine-tuning techniques like Low-Rank Adaptation (LoRA), quantized LoRA (QLoRA), and model pruning on models such as Video-LLaVA and LLaVA-NeXT-Video, we significantly enhance VLM performance in processing remote sensing temporal changes. Results show significant improvements, with the best performance achieving a BERT score of 0.864 and ROUGE-1 score of 0.576, demonstrating superior accuracy in describing land-use transformations.
## QA:
coming soon
