---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Guiomar Pescador-Barrios et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-16 08:00:35'
tags:
- all search terms
- dataset
theme: light
title: How Big is Big Enough Adjusting Model Size in Continual Gaussian Processes
---

# title: How Big is Big Enough Adjusting Model Size in Continual Gaussian Processes 
## publish date: 
**2024-08-14** 
## authors: 
  Guiomar Pescador-Barrios et.al. 
## paper id
2408.07588v1
## download
[2408.07588v1](http://arxiv.org/abs/2408.07588v1)
## abstracts:
For many machine learning methods, creating a model requires setting a parameter that controls the model's capacity before training, e.g.~number of neurons in DNNs, or inducing points in GPs. Increasing capacity improves performance until all the information from the dataset is captured. After this point, computational cost keeps increasing, without improved performance. This leads to the question ``How big is big enough?'' We investigate this problem for Gaussian processes (single-layer neural networks) in continual learning. Here, data becomes available incrementally, and the final dataset size will therefore not be known before training, preventing the use of heuristics for setting the model size. We provide a method that automatically adjusts this, while maintaining near-optimal performance, and show that a single hyperparameter setting for our method performs well across datasets with a wide range of properties.
## QA:
coming soon
