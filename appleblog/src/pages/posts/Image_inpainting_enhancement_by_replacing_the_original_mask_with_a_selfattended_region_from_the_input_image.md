---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Kourosh Kiani et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-11-11 11:35:26'
tags:
- all search terms
- dataset
theme: light
title: Image inpainting enhancement by replacing the original mask with a selfattended
  region from the input image
---

# title: Image inpainting enhancement by replacing the original mask with a selfattended region from the input image 
## publish date: 
**2024-11-08** 
## authors: 
  Kourosh Kiani et.al. 
## paper id
2411.05705v1
## download
[2411.05705v1](http://arxiv.org/abs/2411.05705v1)
## abstracts:
Image inpainting, the process of restoring missing or corrupted regions of an image by reconstructing pixel information, has recently seen considerable advancements through deep learning-based approaches. In this paper, we introduce a novel deep learning-based pre-processing methodology for image inpainting utilizing the Vision Transformer (ViT). Our approach involves replacing masked pixel values with those generated by the ViT, leveraging diverse visual patches within the attention matrix to capture discriminative spatial features. To the best of our knowledge, this is the first instance of such a pre-processing model being proposed for image inpainting tasks. Furthermore, we show that our methodology can be effectively applied using the pre-trained ViT model with pre-defined patch size. To evaluate the generalization capability of the proposed methodology, we provide experimental results comparing our approach with four standard models across four public datasets, demonstrating the efficacy of our pre-processing technique in enhancing inpainting performance.
## QA:
coming soon
