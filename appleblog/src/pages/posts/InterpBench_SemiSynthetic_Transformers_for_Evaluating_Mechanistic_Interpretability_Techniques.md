---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Rohan Gupta et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-07-22 11:32:51'
tags:
- all search terms
- dataset on github
theme: light
title: InterpBench SemiSynthetic Transformers for Evaluating Mechanistic Interpretability
  Techniques
---

# title: InterpBench SemiSynthetic Transformers for Evaluating Mechanistic Interpretability Techniques 
## publish date: 
**2024-07-19** 
## authors: 
  Rohan Gupta et.al. 
## paper id
2407.14494v1
## download
[2407.14494v1](http://arxiv.org/abs/2407.14494v1)
## abstracts:
Mechanistic interpretability methods aim to identify the algorithm a neural network implements, but it is difficult to validate such methods when the true algorithm is unknown. This work presents InterpBench, a collection of semi-synthetic yet realistic transformers with known circuits for evaluating these techniques. We train these neural networks using a stricter version of Interchange Intervention Training (IIT) which we call Strict IIT (SIIT). Like the original, SIIT trains neural networks by aligning their internal computation with a desired high-level causal model, but it also prevents non-circuit nodes from affecting the model's output. We evaluate SIIT on sparse transformers produced by the Tracr tool and find that SIIT models maintain Tracr's original circuit while being more realistic. SIIT can also train transformers with larger circuits, like Indirect Object Identification (IOI). Finally, we use our benchmark to evaluate existing circuit discovery techniques.
## QA:
coming soon
