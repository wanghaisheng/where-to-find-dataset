---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Ann-Kristin Balve et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-26 11:33:38'
tags:
- dataset
- all search terms
theme: light
title: Interpretable breast cancer classification using CNNs on mammographic images
---

# title: Interpretable breast cancer classification using CNNs on mammographic images 
## publish date: 
**2024-08-23** 
## authors: 
  Ann-Kristin Balve et.al. 
## paper id
2408.13154v1
## download
[2408.13154v1](http://arxiv.org/abs/2408.13154v1)
## abstracts:
Deep learning models have achieved promising results in breast cancer classification, yet their 'black-box' nature raises interpretability concerns. This research addresses the crucial need to gain insights into the decision-making process of convolutional neural networks (CNNs) for mammogram classification, specifically focusing on the underlying reasons for the CNN's predictions of breast cancer. For CNNs trained on the Mammographic Image Analysis Society (MIAS) dataset, we compared the post-hoc interpretability techniques LIME, Grad-CAM, and Kernel SHAP in terms of explanatory depth and computational efficiency. The results of this analysis indicate that Grad-CAM, in particular, provides comprehensive insights into the behavior of the CNN, revealing distinctive patterns in normal, benign, and malignant breast tissue. We discuss the implications of the current findings for the use of machine learning models and interpretation techniques in clinical practice.
## QA:
coming soon
