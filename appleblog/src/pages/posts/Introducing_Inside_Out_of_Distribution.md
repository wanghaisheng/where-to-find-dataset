---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Teddy Lazebnik et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-07-09 08:54:52'
tags:
- dataset
- all search terms
theme: light
title: Introducing Inside Out of Distribution
---

# title: Introducing Inside Out of Distribution 
## publish date: 
**2024-07-05** 
## authors: 
  Teddy Lazebnik et.al. 
## paper id
2407.04534v1
## download
[2407.04534v1](http://arxiv.org/abs/2407.04534v1)
## abstracts:
Detecting and understanding out-of-distribution (OOD) samples is crucial in machine learning (ML) to ensure reliable model performance. Current OOD studies, in general, and in the context of ML, in particular, primarily focus on extrapolatory OOD (outside), neglecting potential cases of interpolatory OOD (inside). This study introduces a novel perspective on OOD by suggesting OOD can be divided into inside and outside cases. In addition, following this framework, we examine the inside-outside OOD profiles of datasets and their impact on ML model performance. Our analysis shows that different inside-outside OOD profiles lead to nuanced declines in ML model performance, highlighting the importance of distinguishing between these two cases for developing effective counter-OOD methods.
## QA:
coming soon
