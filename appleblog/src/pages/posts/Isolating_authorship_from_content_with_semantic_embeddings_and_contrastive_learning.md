---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Javier Huertas-Tato et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-02 11:40:43'
tags:
- all search terms
- dataset
theme: light
title: Isolating authorship from content with semantic embeddings and contrastive
  learning
---

# title: Isolating authorship from content with semantic embeddings and contrastive learning 
## publish date: 
**2024-11-27** 
## authors: 
  Javier Huertas-Tato et.al. 
## paper id
2411.18472v1
## download
[2411.18472v1](http://arxiv.org/abs/2411.18472v1)
## abstracts:
Authorship has entangled style and content inside. Authors frequently write about the same topics in the same style, so when different authors write about the exact same topic the easiest way out to distinguish them is by understanding the nuances of their style. Modern neural models for authorship can pick up these features using contrastive learning, however, some amount of content leakage is always present. Our aim is to reduce the inevitable impact and correlation between content and authorship. We present a technique to use contrastive learning (InfoNCE) with additional hard negatives synthetically created using a semantic similarity model. This disentanglement technique aims to distance the content embedding space from the style embedding space, leading to embeddings more informed by style. We demonstrate the performance with ablations on two different datasets and compare them on out-of-domain challenges. Improvements are clearly shown on challenging evaluations on prolific authors with up to a 10% increase in accuracy when the settings are particularly hard. Trials on challenges also demonstrate the preservation of zero-shot capabilities of this method as fine tuning.
## QA:
coming soon
