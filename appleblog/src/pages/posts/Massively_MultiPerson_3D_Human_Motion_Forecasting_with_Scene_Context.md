---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Felix B Mueller et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-09-23 11:35:12'
tags:
- dataset
- all search terms
theme: light
title: Massively MultiPerson 3D Human Motion Forecasting with Scene Context
---

# title: Massively MultiPerson 3D Human Motion Forecasting with Scene Context 
## publish date: 
**2024-09-18** 
## authors: 
  Felix B Mueller et.al. 
## paper id
2409.12189v1
## download
[2409.12189v1](http://arxiv.org/abs/2409.12189v1)
## abstracts:
Forecasting long-term 3D human motion is challenging: the stochasticity of human behavior makes it hard to generate realistic human motion from the input sequence alone. Information on the scene environment and the motion of nearby people can greatly aid the generation process. We propose a scene-aware social transformer model (SAST) to forecast long-term (10s) human motion motion. Unlike previous models, our approach can model interactions between both widely varying numbers of people and objects in a scene. We combine a temporal convolutional encoder-decoder architecture with a Transformer-based bottleneck that allows us to efficiently combine motion and scene information. We model the conditional motion distribution using denoising diffusion models. We benchmark our approach on the Humans in Kitchens dataset, which contains 1 to 16 persons and 29 to 50 objects that are visible simultaneously. Our model outperforms other approaches in terms of realism and diversity on different metrics and in a user study. Code is available at https://github.com/felixbmuller/SAST.
## QA:
coming soon
