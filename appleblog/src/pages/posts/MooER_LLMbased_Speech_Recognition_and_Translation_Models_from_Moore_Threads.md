---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Junhao Xu et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-12 11:32:46'
tags:
- dataset
- all search terms
theme: light
title: MooER LLMbased Speech Recognition and Translation Models from Moore Threads
---

# title: MooER LLMbased Speech Recognition and Translation Models from Moore Threads 
## publish date: 
**2024-08-09** 
## authors: 
  Junhao Xu et.al. 
## paper id
2408.05101v1
## download
[2408.05101v1](http://arxiv.org/abs/2408.05101v1)
## abstracts:
In this paper, we present MooER, a LLM-based large-scale automatic speech recognition (ASR) / automatic speech translation (AST) model of Moore Threads. A 5000h pseudo labeled dataset containing open source and self collected speech data is used for training. We achieve performance comparable to other open source models trained with up to hundreds of thousands of hours of labeled speech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest that our model outperforms other open source Speech LLMs. A BLEU score of 25.2 can be obtained. The main contributions of this paper are summarized as follows. First, this paper presents a training strategy for encoders and LLMs on speech related tasks (including ASR and AST) using a small size of pseudo labeled data without any extra manual annotation and selection. Second, we release our ASR and AST models and plan to open-source our training code and strategy in the near future. Moreover, a model trained on 8wh scale training data is planned to be released later on.
## QA:
coming soon
