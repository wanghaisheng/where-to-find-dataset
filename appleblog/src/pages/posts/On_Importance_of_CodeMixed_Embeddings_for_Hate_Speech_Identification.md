---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Shruti Jagdale et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-02 11:40:41'
tags:
- all search terms
- dataset
theme: light
title: On Importance of CodeMixed Embeddings for Hate Speech Identification
---

# title: On Importance of CodeMixed Embeddings for Hate Speech Identification 
## publish date: 
**2024-11-27** 
## authors: 
  Shruti Jagdale et.al. 
## paper id
2411.18577v1
## download
[2411.18577v1](http://arxiv.org/abs/2411.18577v1)
## abstracts:
Code-mixing is the practice of using two or more languages in a single sentence, which often occurs in multilingual communities such as India where people commonly speak multiple languages. Classic NLP tools, trained on monolingual data, face challenges when dealing with code-mixed data. Extracting meaningful information from sentences containing multiple languages becomes difficult, particularly in tasks like hate speech detection, due to linguistic variation, cultural nuances, and data sparsity. To address this, we aim to analyze the significance of code-mixed embeddings and evaluate the performance of BERT and HingBERT models (trained on a Hindi-English corpus) in hate speech detection. Our study demonstrates that HingBERT models, benefiting from training on the extensive Hindi-English dataset L3Cube-HingCorpus, outperform BERT models when tested on hate speech text datasets. We also found that code-mixed Hing-FastText performs better than standard English FastText and vanilla BERT models.
## QA:
coming soon
