---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Denis Korzhenkov et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-11-04 11:37:42'
tags:
- all search terms
- dataset
theme: light
title: On Sampling Strategies for Spectral Model Sharding
---

# title: On Sampling Strategies for Spectral Model Sharding 
## publish date: 
**2024-10-31** 
## authors: 
  Denis Korzhenkov et.al. 
## paper id
2410.24106v1
## download
[2410.24106v1](http://arxiv.org/abs/2410.24106v1)
## abstracts:
The problem of heterogeneous clients in federated learning has recently drawn a lot of attention. Spectral model sharding, i.e., partitioning the model parameters into low-rank matrices based on the singular value decomposition, has been one of the proposed solutions for more efficient on-device training in such settings. In this work, we present two sampling strategies for such sharding, obtained as solutions to specific optimization problems. The first produces unbiased estimators of the original weights, while the second aims to minimize the squared approximation error. We discuss how both of these estimators can be incorporated in the federated learning loop and practical considerations that arise during local training. Empirically, we demonstrate that both of these methods can lead to improved performance on various commonly used datasets.
## QA:
coming soon
