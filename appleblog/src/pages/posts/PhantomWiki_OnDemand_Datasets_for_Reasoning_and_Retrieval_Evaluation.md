---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Albert Gong et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-03-03 11:38:11'
tags:
- dataset
- all search terms
theme: light
title: PhantomWiki OnDemand Datasets for Reasoning and Retrieval Evaluation
---

# title: PhantomWiki OnDemand Datasets for Reasoning and Retrieval Evaluation 
## publish date: 
**2025-02-27** 
## authors: 
  Albert Gong et.al. 
## paper id
2502.20377v1
## download
[2502.20377v1](http://arxiv.org/abs/2502.20377v1)
## abstracts:
High-quality benchmarks are essential for evaluating reasoning and retrieval capabilities of large language models (LLMs). However, curating datasets for this purpose is not a permanent solution as they are prone to data leakage and inflated performance results. To address these challenges, we propose PhantomWiki: a pipeline to generate unique, factually consistent document corpora with diverse question-answer pairs. Unlike prior work, PhantomWiki is neither a fixed dataset, nor is it based on any existing data. Instead, a new PhantomWiki instance is generated on demand for each evaluation. We vary the question difficulty and corpus size to disentangle reasoning and retrieval capabilities respectively, and find that PhantomWiki datasets are surprisingly challenging for frontier LLMs. Thus, we contribute a scalable and data leakage-resistant framework for disentangled evaluation of reasoning, retrieval, and tool-use abilities. Our code is available at https://github.com/kilian-group/phantom-wiki.
## QA:
coming soon
