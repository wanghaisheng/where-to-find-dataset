---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: "Anders Giovanni M\xF8ller et.al."
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-05 11:32:46'
tags:
- all search terms
- dataset
theme: light
title: Prompt Refinement or Finetuning Best Practices for using LLMs in Computational
  Social Science Tasks
---

# title: Prompt Refinement or Finetuning Best Practices for using LLMs in Computational Social Science Tasks 
## publish date: 
**2024-08-02** 
## authors: 
  Anders Giovanni MÃ¸ller et.al. 
## paper id
2408.01346v1
## download
[2408.01346v1](http://arxiv.org/abs/2408.01346v1)
## abstracts:
Large Language Models are expressive tools that enable complex tasks of text understanding within Computational Social Science. Their versatility, while beneficial, poses a barrier for establishing standardized best practices within the field. To bring clarity on the values of different strategies, we present an overview of the performance of modern LLM-based classification methods on a benchmark of 23 social knowledge tasks. Our results point to three best practices: select models with larger vocabulary and pre-training corpora; avoid simple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific data, and consider more complex forms instruction-tuning on multiple datasets only when only training data is more abundant.
## QA:
coming soon
