---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Jiate Li et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-02-10 11:35:46'
tags:
- all search terms
- dataset
theme: light
title: Provably Robust Explainable Graph Neural Networks against Graph Perturbation
  Attacks
---

# title: Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks 
## publish date: 
**2025-02-06** 
## authors: 
  Jiate Li et.al. 
## paper id
2502.04224v1
## download
[2502.04224v1](http://arxiv.org/abs/2502.04224v1)
## abstracts:
Explaining Graph Neural Network (XGNN) has gained growing attention to facilitate the trust of using GNNs, which is the mainstream method to learn graph data. Despite their growing attention, Existing XGNNs focus on improving the explanation performance, and its robustness under attacks is largely unexplored. We noticed that an adversary can slightly perturb the graph structure such that the explanation result of XGNNs is largely changed. Such vulnerability of XGNNs could cause serious issues particularly in safety/security-critical applications. In this paper, we take the first step to study the robustness of XGNN against graph perturbation attacks, and propose XGNNCert, the first provably robust XGNN. Particularly, our XGNNCert can provably ensure the explanation result for a graph under the worst-case graph perturbation attack is close to that without the attack, while not affecting the GNN prediction, when the number of perturbed edges is bounded. Evaluation results on multiple graph datasets and GNN explainers show the effectiveness of XGNNCert.
## QA:
coming soon
