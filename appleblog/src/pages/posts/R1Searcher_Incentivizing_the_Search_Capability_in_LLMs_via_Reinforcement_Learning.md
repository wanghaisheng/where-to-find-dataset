---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Huatong Song et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-03-10 11:31:50'
tags:
- dataset
- all search terms
theme: light
title: R1Searcher Incentivizing the Search Capability in LLMs via Reinforcement Learning
---

# title: R1Searcher Incentivizing the Search Capability in LLMs via Reinforcement Learning 
## publish date: 
**2025-03-07** 
## authors: 
  Huatong Song et.al. 
## paper id
2503.05592v1
## download
[2503.05592v1](http://arxiv.org/abs/2503.05592v1)
## abstracts:
Existing Large Reasoning Models (LRMs) have shown the potential of reinforcement learning (RL) to enhance the complex reasoning capabilities of Large Language Models~(LLMs). While they achieve remarkable performance on challenging tasks such as mathematics and coding, they often rely on their internal knowledge to solve problems, which can be inadequate for time-sensitive or knowledge-intensive questions, leading to inaccuracies and hallucinations. To address this, we propose \textbf{R1-Searcher}, a novel two-stage outcome-based RL approach designed to enhance the search capabilities of LLMs. This method allows LLMs to autonomously invoke external search systems to access additional knowledge during the reasoning process. Our framework relies exclusively on RL, without requiring process rewards or distillation for a cold start. % effectively generalizing to out-of-domain datasets and supporting both Base and Instruct models. Our experiments demonstrate that our method significantly outperforms previous strong RAG methods, even when compared to the closed-source GPT-4o-mini.
## QA:
coming soon
