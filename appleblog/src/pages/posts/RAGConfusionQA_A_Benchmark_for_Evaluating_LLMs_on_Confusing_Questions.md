---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Zhiyuan Peng et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-10-21 11:37:25'
tags:
- all search terms
- dataset
theme: light
title: RAGConfusionQA A Benchmark for Evaluating LLMs on Confusing Questions
---

# title: RAGConfusionQA A Benchmark for Evaluating LLMs on Confusing Questions 
## publish date: 
**2024-10-18** 
## authors: 
  Zhiyuan Peng et.al. 
## paper id
2410.14567v1
## download
[2410.14567v1](http://arxiv.org/abs/2410.14567v1)
## abstracts:
Conversational AI agents use Retrieval Augmented Generation (RAG) to provide verifiable document-grounded responses to user inquiries. However, many natural questions do not have good answers: about 25\% contain false assumptions~\cite{Yu2023:CREPE}, and over 50\% are ambiguous~\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve their responses to confusing questions. This paper presents a novel synthetic data generation method to efficiently create a diverse set of context-grounded confusing questions from a given document corpus. We conduct an empirical comparative evaluation of several large language models as RAG agents to measure the accuracy of confusion detection and appropriate response generation. We contribute a benchmark dataset to the public domain.
## QA:
coming soon
