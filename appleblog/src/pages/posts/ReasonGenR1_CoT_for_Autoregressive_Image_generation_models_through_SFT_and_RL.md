---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Yu Zhang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-06-02 11:45:57'
tags:
- dataset on github
- all search terms
theme: light
title: ReasonGenR1 CoT for Autoregressive Image generation models through SFT and
  RL
---

# title: ReasonGenR1 CoT for Autoregressive Image generation models through SFT and RL 
## publish date: 
**2025-05-30** 
## authors: 
  Yu Zhang et.al. 
## paper id
2505.24875v1
## download
[2505.24875v1](http://arxiv.org/abs/2505.24875v1)
## abstracts:
Although chain-of-thought reasoning and reinforcement learning (RL) have driven breakthroughs in NLP, their integration into generative vision models remains underexplored. We introduce ReasonGen-R1, a two-stage framework that first imbues an autoregressive image generator with explicit text-based "thinking" skills via supervised fine-tuning on a newly generated reasoning dataset of written rationales, and then refines its outputs using Group Relative Policy Optimization. To enable the model to reason through text before generating images, We automatically generate and release a corpus of model crafted rationales paired with visual prompts, enabling controlled planning of object layouts, styles, and scene compositions. Our GRPO algorithm uses reward signals from a pretrained vision language model to assess overall visual quality, optimizing the policy in each update. Evaluations on GenEval, DPG, and the T2I benchmark demonstrate that ReasonGen-R1 consistently outperforms strong baselines and prior state-of-the-art models. More: aka.ms/reasongen.
## QA:
coming soon
