---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: "Henrique Pi\xF1eiro Monteagudo et.al."
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-02-24 11:36:37'
tags:
- dataset
- all search terms
theme: light
title: RendBEV Semantic Novel View Synthesis for SelfSupervised Birds Eye View Segmentation
---

# title: RendBEV Semantic Novel View Synthesis for SelfSupervised Birds Eye View Segmentation 
## publish date: 
**2025-02-20** 
## authors: 
  Henrique Pi√±eiro Monteagudo et.al. 
## paper id
2502.14792v1
## download
[2502.14792v1](http://arxiv.org/abs/2502.14792v1)
## abstracts:
Bird's Eye View (BEV) semantic maps have recently garnered a lot of attention as a useful representation of the environment to tackle assisted and autonomous driving tasks. However, most of the existing work focuses on the fully supervised setting, training networks on large annotated datasets. In this work, we present RendBEV, a new method for the self-supervised training of BEV semantic segmentation networks, leveraging differentiable volumetric rendering to receive supervision from semantic perspective views computed by a 2D semantic segmentation model. Our method enables zero-shot BEV semantic segmentation, and already delivers competitive results in this challenging setting. When used as pretraining to then fine-tune on labeled BEV ground-truth, our method significantly boosts performance in low-annotation regimes, and sets a new state of the art when fine-tuning on all available labels.
## QA:
coming soon
