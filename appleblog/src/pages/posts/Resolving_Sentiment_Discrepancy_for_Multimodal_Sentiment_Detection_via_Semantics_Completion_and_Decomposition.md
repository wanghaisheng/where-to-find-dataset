---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Daiqing Wu et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-07-10 12:47:26'
tags:
- dataset
- all search terms
theme: light
title: Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics
  Completion and Decomposition
---

# title: Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition 
## publish date: 
**2024-07-09** 
## authors: 
  Daiqing Wu et.al. 
## paper id
2407.07026v1
## download
[2407.07026v1](http://arxiv.org/abs/2407.07026v1)
## abstracts:
With the proliferation of social media posts in recent years, the need to detect sentiments in multimodal (image-text) content has grown rapidly. Since posts are user-generated, the image and text from the same post can express different or even contradictory sentiments, leading to potential \textbf{sentiment discrepancy}. However, existing works mainly adopt a single-branch fusion structure that primarily captures the consistent sentiment between image and text. The ignorance or implicit modeling of discrepant sentiment results in compromised unimodal encoding and limited performances. In this paper, we propose a semantics Completion and Decomposition (CoDe) network to resolve the above issue. In the semantics completion module, we complement image and text representations with the semantics of the OCR text embedded in the image, helping bridge the sentiment gap. In the semantics decomposition module, we decompose image and text representations with exclusive projection and contrastive learning, thereby explicitly capturing the discrepant sentiment between modalities. Finally, we fuse image and text representations by cross-attention and combine them with the learned discrepant sentiment for final classification. Extensive experiments conducted on four multimodal sentiment datasets demonstrate the superiority of CoDe against SOTA methods.
## QA:
coming soon
