---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Andrea Santilli et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-04-21 11:43:05'
tags:
- all search terms
- dataset
theme: light
title: Revisiting Uncertainty Quantification Evaluation in Language Models Spurious
  Interactions with Response Length Bias Results
---

# title: Revisiting Uncertainty Quantification Evaluation in Language Models Spurious Interactions with Response Length Bias Results 
## publish date: 
**2025-04-18** 
## authors: 
  Andrea Santilli et.al. 
## paper id
2504.13677v1
## download
[2504.13677v1](http://arxiv.org/abs/2504.13677v1)
## abstracts:
Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases.
## QA:
coming soon
