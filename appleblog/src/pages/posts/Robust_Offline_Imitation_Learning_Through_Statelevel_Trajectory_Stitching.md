---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Shuze Wang et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-03-31 11:40:24'
tags:
- all search terms
- dataset
theme: light
title: Robust Offline Imitation Learning Through Statelevel Trajectory Stitching
---

# title: Robust Offline Imitation Learning Through Statelevel Trajectory Stitching 
## publish date: 
**2025-03-28** 
## authors: 
  Shuze Wang et.al. 
## paper id
2503.22524v1
## download
[2503.22524v1](http://arxiv.org/abs/2503.22524v1)
## abstracts:
Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.
## QA:
coming soon
