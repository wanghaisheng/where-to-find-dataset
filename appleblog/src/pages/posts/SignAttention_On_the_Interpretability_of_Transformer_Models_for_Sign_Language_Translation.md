---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Pedro Alejandro Dal Bianco et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-10-21 11:37:26'
tags:
- all search terms
- dataset
theme: light
title: SignAttention On the Interpretability of Transformer Models for Sign Language
  Translation
---

# title: SignAttention On the Interpretability of Transformer Models for Sign Language Translation 
## publish date: 
**2024-10-18** 
## authors: 
  Pedro Alejandro Dal Bianco et.al. 
## paper id
2410.14506v1
## download
[2410.14506v1](http://arxiv.org/abs/2410.14506v1)
## abstracts:
This paper presents the first comprehensive interpretability analysis of a Transformer-based Sign Language Translation (SLT) model, focusing on the translation from video-based Greek Sign Language to glosses and text. Leveraging the Greek Sign Language Dataset, we examine the attention mechanisms within the model to understand how it processes and aligns visual input with sequential glosses. Our analysis reveals that the model pays attention to clusters of frames rather than individual ones, with a diagonal alignment pattern emerging between poses and glosses, which becomes less distinct as the number of glosses increases. We also explore the relative contributions of cross-attention and self-attention at each decoding step, finding that the model initially relies on video frames but shifts its focus to previously predicted tokens as the translation progresses. This work contributes to a deeper understanding of SLT models, paving the way for the development of more transparent and reliable translation systems essential for real-world applications.
## QA:
coming soon
