---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Samin Yeasar Arnob et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-06-23 11:47:44'
tags:
- all search terms
- dataset
theme: light
title: SparseReg Improving Sample Complexity in Offline Reinforcement Learning using
  Sparsity
---

# title: SparseReg Improving Sample Complexity in Offline Reinforcement Learning using Sparsity 
## publish date: 
**2025-06-20** 
## authors: 
  Samin Yeasar Arnob et.al. 
## paper id
2506.17155v1
## download
[2506.17155v1](http://arxiv.org/abs/2506.17155v1)
## abstracts:
In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce "Sparse-Reg": a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.
## QA:
coming soon
