---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Prashanth Chandran et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-04-07 11:39:44'
tags:
- all search terms
- dataset
theme: light
title: Splinebased Transformers
---

# title: Splinebased Transformers 
## publish date: 
**2025-04-03** 
## authors: 
  Prashanth Chandran et.al. 
## paper id
2504.02797v1
## download
[2504.02797v1](http://arxiv.org/abs/2504.02797v1)
## abstracts:
We introduce Spline-based Transformers, a novel class of Transformer models that eliminate the need for positional encoding. Inspired by workflows using splines in computer animation, our Spline-based Transformers embed an input sequence of elements as a smooth trajectory in latent space. Overcoming drawbacks of positional encoding such as sequence length extrapolation, Spline-based Transformers also provide a novel way for users to interact with transformer latent spaces by directly manipulating the latent control points to create new latent trajectories and sequences. We demonstrate the superior performance of our approach in comparison to conventional positional encoding on a variety of datasets, ranging from synthetic 2D to large-scale real-world datasets of images, 3D shapes, and animations.
## QA:
coming soon
