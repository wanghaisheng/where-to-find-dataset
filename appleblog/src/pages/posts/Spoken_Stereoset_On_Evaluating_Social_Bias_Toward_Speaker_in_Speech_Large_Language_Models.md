---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Yi-Cheng Lin et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-16 08:00:32'
tags:
- all search terms
- dataset
theme: light
title: Spoken Stereoset On Evaluating Social Bias Toward Speaker in Speech Large Language
  Models
---

# title: Spoken Stereoset On Evaluating Social Bias Toward Speaker in Speech Large Language Models 
## publish date: 
**2024-08-14** 
## authors: 
  Yi-Cheng Lin et.al. 
## paper id
2408.07665v1
## download
[2408.07665v1](http://arxiv.org/abs/2408.07665v1)
## abstracts:
Warning: This paper may contain texts with uncomfortable content.   Large Language Models (LLMs) have achieved remarkable performance in various tasks, including those involving multimodal data like speech. However, these models often exhibit biases due to the nature of their training data. Recently, more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent need to address these biases. This study introduces Spoken Stereoset, a dataset specifically designed to evaluate social biases in SLLMs. By examining how different models respond to speech from diverse demographic groups, we aim to identify these biases. Our experiments reveal significant insights into their performance and bias levels. The findings indicate that while most models show minimal bias, some still exhibit slightly stereotypical or anti-stereotypical tendencies.
## QA:
coming soon
