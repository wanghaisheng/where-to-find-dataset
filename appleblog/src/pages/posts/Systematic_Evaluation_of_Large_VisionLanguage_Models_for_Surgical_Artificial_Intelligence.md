---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Anita Rau et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-04-07 11:39:44'
tags:
- all search terms
- dataset
theme: light
title: Systematic Evaluation of Large VisionLanguage Models for Surgical Artificial
  Intelligence
---

# title: Systematic Evaluation of Large VisionLanguage Models for Surgical Artificial Intelligence 
## publish date: 
**2025-04-03** 
## authors: 
  Anita Rau et.al. 
## paper id
2504.02799v1
## download
[2504.02799v1](http://arxiv.org/abs/2504.02799v1)
## abstracts:
Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training. This flexibility holds particular promise across medicine, where expert-annotated data is scarce. Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain. Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures. In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting. In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength. Still, tasks requiring spatial or temporal reasoning remained difficult. Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications.
## QA:
coming soon
