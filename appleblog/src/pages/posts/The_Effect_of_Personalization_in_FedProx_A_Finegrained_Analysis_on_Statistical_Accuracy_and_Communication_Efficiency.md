---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Xin Yu et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-10-14 11:37:34'
tags:
- all search terms
- dataset
theme: light
title: The Effect of Personalization in FedProx A Finegrained Analysis on Statistical
  Accuracy and Communication Efficiency
---

# title: The Effect of Personalization in FedProx A Finegrained Analysis on Statistical Accuracy and Communication Efficiency 
## publish date: 
**2024-10-11** 
## authors: 
  Xin Yu et.al. 
## paper id
2410.08934v1
## download
[2410.08934v1](http://arxiv.org/abs/2410.08934v1)
## abstracts:
FedProx is a simple yet effective federated learning method that enables model personalization via regularization. Despite remarkable success in practice, a rigorous analysis of how such a regularization provably improves the statistical accuracy of each client's local model hasn't been fully established. Setting the regularization strength heuristically presents a risk, as an inappropriate choice may even degrade accuracy. This work fills in the gap by analyzing the effect of regularization on statistical accuracy, thereby providing a theoretical guideline for setting the regularization strength for achieving personalization. We prove that by adaptively choosing the regularization strength under different statistical heterogeneity, FedProx can consistently outperform pure local training and achieve a nearly minimax-optimal statistical rate. In addition, to shed light on resource allocation, we design an algorithm, provably showing that stronger personalization reduces communication complexity without increasing the computation cost overhead. Finally, our theory is validated on both synthetic and real-world datasets and its generalizability is verified in a non-convex setting.
## QA:
coming soon
