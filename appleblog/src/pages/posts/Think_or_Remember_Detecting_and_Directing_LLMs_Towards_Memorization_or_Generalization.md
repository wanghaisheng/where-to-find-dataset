---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Yi-Fu Fu et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-30 11:35:43'
tags:
- all search terms
- dataset
theme: light
title: Think or Remember Detecting and Directing LLMs Towards Memorization or Generalization
---

# title: Think or Remember Detecting and Directing LLMs Towards Memorization or Generalization 
## publish date: 
**2024-12-24** 
## authors: 
  Yi-Fu Fu et.al. 
## paper id
2412.18497v1
## download
[2412.18497v1](http://arxiv.org/abs/2412.18497v1)
## abstracts:
In this paper, we explore the foundational mechanisms of memorization and generalization in Large Language Models (LLMs), inspired by the functional specialization observed in the human brain. Our investigation serves as a case study leveraging specially designed datasets and experimental-scale LLMs to lay the groundwork for understanding these behaviors. Specifically, we aim to first enable LLMs to exhibit both memorization and generalization by training with the designed dataset, then (a) examine whether LLMs exhibit neuron-level spatial differentiation for memorization and generalization, (b) predict these behaviors using model internal representations, and (c) steer the behaviors through inference-time interventions. Our findings reveal that neuron-wise differentiation of memorization and generalization is observable in LLMs, and targeted interventions can successfully direct their behavior.
## QA:
coming soon
