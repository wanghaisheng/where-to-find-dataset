---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Hasan Md Tusfiqur Alam et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-12-24 01:27:48'
tags:
- all search terms
- dataset
theme: light
title: Towards Interpretable Radiology Report Generation via Concept Bottlenecks using
  a MultiAgentic RAG
---

# title: Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a MultiAgentic RAG 
## publish date: 
**2024-12-20** 
## authors: 
  Hasan Md Tusfiqur Alam et.al. 
## paper id
2412.16086v1
## download
[2412.16086v1](http://arxiv.org/abs/2412.16086v1)
## abstracts:
Deep learning has advanced medical image classification, but interpretability challenges hinder its clinical adoption. This study enhances interpretability in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs) and a multi-agent Retrieval-Augmented Generation (RAG) system for report generation. By modeling relationships between visual features and clinical concepts, we create interpretable concept vectors that guide a multi-agent RAG system to generate radiology reports, enhancing clinical relevance, explainability, and transparency. Evaluation of the generated reports using an LLM-as-a-judge confirmed the interpretability and clinical utility of our model's outputs. On the COVID-QU dataset, our model achieved 81% classification accuracy and demonstrated robust report generation performance, with five key metrics ranging between 84% and 90%. This interpretable multi-agent framework bridges the gap between high-performance AI and the explainability required for reliable AI-driven CXR analysis in clinical settings.
## QA:
coming soon
