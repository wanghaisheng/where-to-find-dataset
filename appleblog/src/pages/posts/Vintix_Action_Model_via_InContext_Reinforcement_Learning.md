---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Andrey Polubarov et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-02-03 11:34:51'
tags:
- all search terms
- dataset on github
theme: light
title: Vintix Action Model via InContext Reinforcement Learning
---

# title: Vintix Action Model via InContext Reinforcement Learning 
## publish date: 
**2025-01-31** 
## authors: 
  Andrey Polubarov et.al. 
## paper id
2501.19400v1
## download
[2501.19400v1](http://arxiv.org/abs/2501.19400v1)
## abstracts:
In-Context Reinforcement Learning (ICRL) represents a promising paradigm for developing generalist agents that learn at inference time through trial-and-error interactions, analogous to how large language models adapt contextually, but with a focus on reward maximization. However, the scalability of ICRL beyond toy tasks and single-domain settings remains an open challenge. In this work, we present the first steps toward scaling ICRL by introducing a fixed, cross-domain model capable of learning behaviors through in-context reinforcement learning. Our results demonstrate that Algorithm Distillation, a framework designed to facilitate ICRL, offers a compelling and competitive alternative to expert distillation to construct versatile action models. These findings highlight the potential of ICRL as a scalable approach for generalist decision-making systems. Code to be released at https://github.com/dunnolab/vintix
## QA:
coming soon
