---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Mouxiang Chen et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-09-02 11:33:09'
tags:
- dataset
- all search terms
theme: light
title: VisionTS Visual Masked Autoencoders Are FreeLunch ZeroShot Time Series Forecasters
---

# title: VisionTS Visual Masked Autoencoders Are FreeLunch ZeroShot Time Series Forecasters 
## publish date: 
**2024-08-30** 
## authors: 
  Mouxiang Chen et.al. 
## paper id
2408.17253v1
## download
[2408.17253v1](http://arxiv.org/abs/2408.17253v1)
## abstracts:
Foundation models have emerged as a promising approach in time series forecasting (TSF). Existing approaches either fine-tune large language models (LLMs) or build large-scale time-series datasets to develop TSF foundation models. However, these methods face challenges due to the severe cross-domain gap or in-domain heterogeneity. In this paper, we explore a new road to building a TSF foundation model from rich and high-quality natural images, based on the intrinsic similarities between images and time series. To bridge the gap between the two domains, we reformulate the TSF task as an image reconstruction task, which is further processed by a visual masked autoencoder (MAE) self-supervised pre-trained on the ImageNet dataset. Surprisingly, without further adaptation in the time-series domain, the proposed VisionTS could achieve superior zero-shot forecasting performance compared to existing TSF foundation models. With minimal fine-tuning, VisionTS could further improve the forecasting and achieve state-of-the-art performance in most cases. These findings suggest that visual models could be a free lunch for TSF and highlight the potential for future cross-domain research between computer vision and TSF. Our code is publicly available at https://github.com/Keytoyze/VisionTS.
## QA:
coming soon
