---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Petr Grinberg et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2025-01-27 11:33:54'
tags:
- all search terms
- dataset
theme: light
title: What Does an Audio Deepfake Detector Focus on A Study in the Time Domain
---

# title: What Does an Audio Deepfake Detector Focus on A Study in the Time Domain 
## publish date: 
**2025-01-23** 
## authors: 
  Petr Grinberg et.al. 
## paper id
2501.13887v1
## download
[2501.13887v1](http://arxiv.org/abs/2501.13887v1)
## abstracts:
Adding explanations to audio deepfake detection (ADD) models will boost their real-world application by providing insight on the decision making process. In this paper, we propose a relevancy-based explainable AI (XAI) method to analyze the predictions of transformer-based ADD models. We compare against standard Grad-CAM and SHAP-based methods, using quantitative faithfulness metrics as well as a partial spoof test, to comprehensively analyze the relative importance of different temporal regions in an audio. We consider large datasets, unlike previous works where only limited utterances are studied, and find that the XAI methods differ in their explanations. The proposed relevancy-based XAI method performs the best overall on a variety of metrics. Further investigation on the relative importance of speech/non-speech, phonetic content, and voice onsets/offsets suggest that the XAI results obtained from analyzing limited utterances don't necessarily hold when evaluated on large datasets.
## QA:
coming soon
