---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: "Andr\xE1s Kalapos et.al."
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-08-16 08:00:38'
tags:
- all search terms
- dataset
theme: light
title: Whitening Consistently Improves SelfSupervised Learning
---

# title: Whitening Consistently Improves SelfSupervised Learning 
## publish date: 
**2024-08-14** 
## authors: 
  Andr√°s Kalapos et.al. 
## paper id
2408.07519v1
## download
[2408.07519v1](http://arxiv.org/abs/2408.07519v1)
## abstracts:
Self-supervised learning (SSL) has been shown to be a powerful approach for learning visual representations. In this study, we propose incorporating ZCA whitening as the final layer of the encoder in self-supervised learning to enhance the quality of learned features by normalizing and decorrelating them. Although whitening has been utilized in SSL in previous works, its potential to universally improve any SSL model has not been explored. We demonstrate that adding whitening as the last layer of SSL pretrained encoders is independent of the self-supervised learning method and encoder architecture, thus it improves performance for a wide range of SSL methods across multiple encoder architectures and datasets. Our experiments show that whitening is capable of improving linear and k-NN probing accuracy by 1-5%. Additionally, we propose metrics that allow for a comprehensive analysis of the learned features, provide insights into the quality of the representations and help identify collapse patterns.
## QA:
coming soon
