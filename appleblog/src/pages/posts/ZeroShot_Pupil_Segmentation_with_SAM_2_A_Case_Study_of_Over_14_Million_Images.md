---
author: wanghaisheng
cover:
  alt: cover
  square: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
  url: https://www.apple.com.cn/newsroom/images/product/homepod/standard/Apple-HomePod-hero-230118_big.jpg.large_2x.jpg
description: ''
featured: true
keywords: key1, key2, key3
layout: ../../layouts/MarkdownPost.astro
meta:
- content: Virmarie Maquiling et.al.
  name: author
- content: key3, key4
  name: keywords
pubDate: '2024-10-14 11:37:35'
tags:
- all search terms
- dataset
theme: light
title: ZeroShot Pupil Segmentation with SAM 2 A Case Study of Over 14 Million Images
---

# title: ZeroShot Pupil Segmentation with SAM 2 A Case Study of Over 14 Million Images 
## publish date: 
**2024-10-11** 
## authors: 
  Virmarie Maquiling et.al. 
## paper id
2410.08926v1
## download
[2410.08926v1](http://arxiv.org/abs/2410.08926v1)
## abstracts:
We explore the transformative potential of SAM 2, a vision foundation model, in advancing gaze estimation and eye tracking technologies. By significantly reducing annotation time, lowering technical barriers through its ease of deployment, and enhancing segmentation accuracy, SAM 2 addresses critical challenges faced by researchers and practitioners. Utilizing its zero-shot segmentation capabilities with minimal user input-a single click per video-we tested SAM 2 on over 14 million eye images from diverse datasets, including virtual reality setups and the world's largest unified dataset recorded using wearable eye trackers. Remarkably, in pupil segmentation tasks, SAM 2 matches the performance of domain-specific models trained solely on eye images, achieving competitive mean Intersection over Union (mIoU) scores of up to 93% without fine-tuning. Additionally, we provide our code and segmentation masks for these widely used datasets to promote further research.
## QA:
coming soon
